import streamlit as st
import random
import os

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity

    _SKLEARN_AVAILABLE = True
except ImportError:
    _SKLEARN_AVAILABLE = False

try:
    import spacy

    _SPACY_AVAILABLE = True
except ImportError:
    _SPACY_AVAILABLE = False

try:
    import Levenshtein

    _LEVENSHTEIN_AVAILABLE = True
except ImportError:
    _LEVENSHTEIN_AVAILABLE = False


# Определим алфавит для генерации случайных букв (русские строчные + пробел)
# Используем стандартный русский алфавит. Добавим пробел, т.к. он часто встречается в текстах.
RUSSIAN_ALPHABET = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '

# --- Функции Генерации Текстов ---
def generate_random_letters(length: int) -> str:
    """Генерирует строку заданной длины из случайных символов русского алфавита и пробела."""
    if length <= 0:
        return ""
    return ''.join(random.choices(RUSSIAN_ALPHABET, k=length))

@st.cache_resource
def load_spacy_model(model_name: str = "ru_core_news_md"):
    """Загружает и кэширует языковую модель spaCy."""
    if not _SPACY_AVAILABLE:
        return None
    try:
        nlp = spacy.load(model_name, disable=['parser', 'ner'])
        st.success(f"Модель spaCy '{model_name}' успешно загружена и кэширована.")
        return nlp
    except OSError:
        st.error(f"❌ Модель spaCy '{model_name}' не найдена. "
                 f"Пожалуйста, скачайте её, выполнив в терминале: "
                 f"python -m spacy download {model_name}")
        return None
    except Exception as e:
        st.error(f"❌ Не удалось загрузить модель spaCy '{model_name}': {e}")
        return None

@st.cache_data
def load_word_list(filepath: str = "russian.txt") -> list[str]:
    """
    Загружает список слов из указанного файла.
    Обрабатывает строки: удаляет пробельные символы по краям
    (включая символ переноса строки '\n') и игнорирует пустые строки.

    Args:
        filepath (str): Путь к файлу со списком слов (по одному слову на строку).

    Returns:
        list[str]: Список загруженных слов.
                   Если файл не найден, пуст или произошла ошибка чтения,
                   возвращает небольшой стандартный список и выводит сообщение
                   в интерфейс Streamlit.
    """
    # Стандартный список слов на случай, если файл не найден или пуст
    default_word_list = [
        "текст", "слово", "буква", "язык", "анализ", "файл", "список", "случайный",
        "генерация", "алгоритм", "сравнение", "система", "программа", "данные",
        "вероятность", "статистика", "результат", "отчет", "интерфейс", "код"
    ]

    word_list = []

    # Проверяем, существует ли файл
    if not os.path.exists(filepath):
        st.warning(f"⚠️ Файл словаря '{filepath}' не найден. "
                   f"Будет использован стандартный небольшой словарь.")
        return default_word_list

    try:
        with open(filepath, 'r', encoding='windows-1251') as f:
            lines = f.readlines()
            # Обрабатываем каждую строку: убираем пробелы/переносы по краям (.strip())
            # и добавляем в список, только если строка после этого не пустая.
            word_list = [line.strip() for line in lines if line.strip()]

        # Проверяем, не оказался ли список пустым после обработки
        if not word_list:
            st.warning(f"⚠️ Файл словаря '{filepath}' пуст или не содержит допустимых слов "
                       f"после очистки. Будет использован стандартный небольшой словарь.")
            return default_word_list

        st.success(f"Словарь '{filepath}' успешно загружен и кэширован. "
                   f"Количество слов: {len(word_list):,}")
        return word_list

    except Exception as e:
        st.error(f"❌ Ошибка при чтении файла словаря '{filepath}': {e}. "
                 f"Будет использован стандартный небольшой словарь.")
        return default_word_list


# --- Обновленная функция генерации случайных слов ---
def generate_random_words(length: int, word_list_filepath: str = "russian.txt") -> str:
    """
    Генерирует строку заданной длины из случайных слов, взятых из файла словаря.
    Слова разделяются одним пробелом. Результат обрезается до точной длины `length`.

    Args:
        length (int): Требуемая длина итоговой строки.
        word_list_filepath (str): Путь к файлу словаря для функции load_word_list.

    Returns:
        str: Строка, состоящая из случайных слов, заданной длины.
             В случае проблем с загрузкой словаря или если length <= 0,
             может вернуть пустую строку или строку из случайных букв
             (если словарь недоступен).
    """
    if length <= 0:
        return ""

    # Загружаем (или получаем из кэша) список слов
    # Функция load_word_list сама обработает ошибки и вернет либо слова из файла,
    # либо стандартный список.
    actual_word_list = load_word_list(word_list_filepath)

    # Дополнительная проверка на случай, если даже стандартный список не сработал
    # (хотя он задан жестко, но для надежности)
    if not actual_word_list:
        st.error("Не удалось получить список слов (даже стандартный). "
                 "Генерация случайных слов невозможна.")
        # Возвращаем пустую строку или можно сгенерировать случайные буквы как запасной вариант
        return ""

    result_text = ""
    separator = " "

    # Генерируем текст, пока его длина не достигнет или немного не превысит требуемую
    while len(result_text) < length:
        word = random.choice(actual_word_list)

        # Определяем, нужно ли добавлять разделитель (пробел)
        # Пробел нужен, если текст уже не пустой
        add_separator = len(result_text) > 0

        # Длина добавляемого фрагмента (пробел + слово)
        fragment_len = len(word) + (len(separator) if add_separator else 0)

        # Проверяем, поместится ли новый фрагмент хотя бы частично
        # Если даже первый символ фрагмента не влезает, останавливаемся
        if len(result_text) + (1 if add_separator else 0) > length:
            break

        # Добавляем фрагмент (пробел + слово или просто слово)
        if add_separator:
            result_text += separator + word
        else:
            result_text += word

        # Небольшая оптимизация: если длина уже сильно превысила нужную, можно прерваться раньше,
        # т.к. все равно будем обрезать. Множитель 1.1 дает небольшой запас.
        if len(result_text) > length * 1.1:
            break

    # Обрезаем результат до ТОЧНОЙ требуемой длины
    # Простое срезание [:length] является наиболее прямым способом
    # выполнить требование задачи о строгой длине.
    return result_text[:length]


# --- Функция Сравнения Текстов ---
def compare_texts(text1: str, text2: str) -> tuple[str, float | None]:
    """
    Сравнивает два текста посимвольно.
    Возвращает кортеж: (сообщение о результате, процент совпадений или None).
    """
    len1 = len(text1)
    len2 = len(text2)

    # Обработка пустых строк
    if len1 == 0 or len2 == 0:
        return "Ошибка: Один или оба текста пусты. Сравнение невозможно.", None

    # Проверка на совпадение длины
    if len1 != len2:
        diff = abs(len1 - len2)
        if len1 > len2:
            msg = f"Ошибка: Текст 1 ({len1} симв.) длиннее Текста 2 ({len2} симв.) на {diff} символов. Сравнение по данному алгоритму требует одинаковой длины."
        else:
            msg = f"Ошибка: Текст 2 ({len2} симв.) длиннее Текста 1 ({len1} симв.) на {diff} символов. Сравнение по данному алгоритму требует одинаковой длины."
        return msg, None
    else:
        # Подсчет совпадений
        matches = 0
        for i in range(len1):
            if text1[i] == text2[i]:
                matches += 1

        # Расчет процента совпадений
        percentage = matches / len1
        msg = f"Сравнение успешно. Длина текстов: {len1}. Количество совпадений символов на тех же позициях: {matches}."
        return msg, percentage

def calculate_tfidf_similarity(text1: str, text2: str) -> tuple[str, float | None]:
    """Вычисляет косинусное сходство на основе TF-IDF векторов."""
    if not _SKLEARN_AVAILABLE:
        return "Ошибка: Библиотека scikit-learn не найдена.", None
    if not text1 or not text2:
        return "Ошибка: Один или оба текста пусты для TF-IDF.", None

    try:
        vectorizer = TfidfVectorizer()
        # Создаем матрицу TF-IDF для обоих текстов вместе
        tfidf_matrix = vectorizer.fit_transform([text1, text2])
        # Вычисляем косинусное сходство между первым и вторым вектором
        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
        msg = "TF-IDF косинусное сходство успешно рассчитано."
        return msg, float(similarity)  # Убедимся, что возвращаем float
    except Exception as e:
        return f"Ошибка при расчете TF-IDF: {e}", None


def calculate_embedding_similarity(text1: str, text2: str, nlp_model) -> tuple[str, float | None]:
    """Вычисляет косинусное сходство на основе векторов документов spaCy."""
    if not _SPACY_AVAILABLE or nlp_model is None:
        return "Ошибка: Модель spaCy недоступна.", None
    if not text1 or not text2:
        return "Ошибка: Один или оба текста пусты для Embedding.", None

    try:
        doc1 = nlp_model(text1)
        doc2 = nlp_model(text2)

        # Проверяем, есть ли у документов векторы и их норма не равна нулю
        if not doc1.has_vector or not doc2.has_vector or doc1.vector_norm == 0 or doc2.vector_norm == 0:
            # Это может случиться, если тексты состоят только из OOV слов или пробелов
            msg = ("Предупреждение: Не удалось получить валидные векторы для одного или обоих текстов "
                   "(возможно, они содержат только неизвестные слова или пробелы). Сходство установлено в 0.")
            return msg, 0.0

        similarity = doc1.similarity(doc2)
        # В редких случаях spaCy может вернуть значение чуть вне [-1, 1] из-за точности float
        similarity = max(-1.0, min(1.0, similarity))
        msg = "Сходство на основе Embeddings (spaCy) успешно рассчитано."
        # Косинусное сходство может быть отрицательным, но обычно для текстов оно >= 0
        # Для единообразия с TF-IDF и Levenshtein (которые 0..1), можно оставить как есть
        # или привести к [0, 1], например, (similarity + 1) / 2, но это исказит смысл.
        # Оставляем в диапазоне [-1, 1], но чаще будет [0, 1].
        return msg, float(similarity)
    except Exception as e:
        return f"Ошибка при расчете Embedding сходства: {e}", None


def calculate_levenshtein_similarity(text1: str, text2: str) -> tuple[str, float | None]:
    """Вычисляет нормализованное сходство на основе расстояния Левенштейна."""
    if not _LEVENSHTEIN_AVAILABLE:
        return "Ошибка: Библиотека python-Levenshtein не найдена.", None

    len1 = len(text1)
    len2 = len(text2)

    # Если оба текста пусты, они идентичны
    if len1 == 0 and len2 == 0:
        return "Расстояние Левенштейна: оба текста пусты.", 1.0
    # Если один пуст, сходство 0
    if len1 == 0 or len2 == 0:
        # Расстояние равно длине непустой строки, нормализованное сходство = 0
        return "Расстояние Левенштейна: один из текстов пуст.", 0.0

    try:
        distance = Levenshtein.distance(text1, text2)
        # Нормализуем расстояние: 1 - (расстояние / максимальная длина)
        # Это дает значение от 0 (совершенно разные) до 1 (идентичные)
        max_len = max(len1, len2)
        similarity = 1.0 - (distance / max_len)
        msg = f"Расстояние Левенштейна = {distance}. Нормализованное сходство рассчитано."
        return msg, float(similarity)
    except Exception as e:
        return f"Ошибка при расчете расстояния Левенштейна: {e}", None


# --- Streamlit Интерфейс ---
st.title("Инструмент для Сравнения Текстов")
st.caption("Посимвольное сравнение, TF-IDF, Векторы (Embeddings), Левенштейн")

# --- Загрузка модели spaCy (делаем один раз при старте/перезапуске) ---
# Модель будет загружена при первом обращении, если она доступна
nlp_model = None
if _SPACY_AVAILABLE:
    nlp_model = load_spacy_model()
    if nlp_model is None and _SPACY_AVAILABLE:
        st.sidebar.warning("Модель spaCy не загружена. Сравнение на основе векторов будет недоступно.")
    elif not _SPACY_AVAILABLE:
        st.sidebar.warning("Библиотека spaCy не установлена. Сравнение на основе векторов недоступно.")

# --- Боковая панель ---
st.sidebar.header("Параметры Сравнения")
# Регулировка длины генерируемых текстов
text_length = st.sidebar.number_input(
    "Желаемая длина генерируемых/сравниваемых текстов:",
    min_value=10,
    max_value=10000,
    value=300,
    step=50,
    help="Укажите длину в символах для генерируемых случайных текстов и для приведения естественных текстов к этой длине при необходимости."
)

st.sidebar.header("Ввод Естественных Текстов")
# Формы для вставки естественных текстов
nat_text1_input = st.sidebar.text_area(
    "Естественный текст 1:",
    height=150,
    key="nat1",
    placeholder="Вставьте сюда первый осмысленный текст..."
)
nat_text2_input = st.sidebar.text_area(
    "Естественный текст 2:",
    height=150,
    key="nat2",
    placeholder="Вставьте сюда второй осмысленный текст..."
)

# Кнопка для запуска анализа
run_button = st.sidebar.button("🚀 Запустить Сравнение и Анализ")

# Основная область для вывода результатов и отчета
st.markdown("---")
st.header("Результаты Сравнения и Отчет")

if run_button:
    # --- Подготовка текстов ---
    results = {}
    texts_used = {}
    comparison_log = []

    # 1. Естественный текст vs Естественный текст
    st.subheader("1. Естественный текст vs Естественный текст")
    st.markdown("**1.1 Посимвольное Сходство**")
    msg, perc = compare_texts(nat_text1_input, nat_text2_input)
    comparison_log.append(f"1. Natural vs Natural (Symbolwise): {msg}")
    st.info(msg)
    if perc is not None:
        st.metric("Процент совпадения", f"{perc:.4f}")
        results['Natural vs Natural'] = perc
        texts_used['Natural 1'] = nat_text1_input
        texts_used['Natural 2'] = nat_text2_input
    else:
        st.metric("Процент совпадения", "N/A")
        results['Natural vs Natural'] = None
        texts_used['Natural 1'] = nat_text1_input
        texts_used['Natural 2'] = nat_text2_input
    st.markdown("---")

    # --- TF-IDF ---
    st.markdown("**1.2 TF-IDF Косинусное Сходство**")
    if not _SKLEARN_AVAILABLE:
        st.warning("Библиотека scikit-learn не установлена. Расчет TF-IDF невозможен.")
    else:
        msg_tfidf, perc_tfidf = calculate_tfidf_similarity(nat_text1_input, nat_text2_input)
        comparison_log.append(f"2.1 Natural vs Natural (TF-IDF): {msg_tfidf}")
        if perc_tfidf is not None:
            st.info(msg_tfidf)
            st.metric("TF-IDF Сходство", f"{perc_tfidf:.4f}")
            results['Natural vs Natural (TF-IDF)'] = perc_tfidf
        else:
            st.warning(msg_tfidf)
            st.metric("TF-IDF Сходство", "N/A")
            results['Natural vs Natural (TF-IDF)'] = None
        st.caption(
            "Измеряет сходство на основе частоты встречаемости слов, взвешенных по их важности в коллекции текстов (здесь - только в этих двух). 1 = очень похожи по словам, 0 = нет общих слов (кроме стоп-слов).")

    # --- Embedding Similarity ---
    st.markdown("**1.3 Сходство на Основе Векторов (Embeddings)**")
    if not _SPACY_AVAILABLE:
        st.warning("Библиотека spaCy не установлена. Сравнение на основе векторов невозможно.")
    elif nlp_model is None:
        st.warning("Модель spaCy не загружена. Сравнение на основе векторов невозможно.")
    else:
        msg_emb, perc_emb = calculate_embedding_similarity(nat_text1_input, nat_text2_input, nlp_model)
        comparison_log.append(f"2.2 Natural vs Natural (Embedding): {msg_emb}")
        if perc_emb is not None:
            if "Предупреждение" in msg_emb:
                st.warning(msg_emb)
            else:
                st.info(msg_emb)
            st.metric("Embedding Сходство (spaCy)", f"{perc_emb:.4f}")
            results['Natural vs Natural (Embedding)'] = perc_emb
        else:
            st.error(msg_emb)  # Используем error для ошибок spaCy
            st.metric("Embedding Сходство (spaCy)", "N/A")
            results['Natural vs Natural (Embedding)'] = None
        st.caption(
            "Измеряет семантическое (смысловое) сходство текстов на основе усредненных векторов слов. Значения от -1 до 1 (чаще 0..1). 1 = очень близки по смыслу, 0 = ортогональны (не связаны), -1 = противоположны (редко).")

    # --- Levenshtein Similarity ---
    st.markdown("**1.4 Сходство Левенштейна (Нормализованное)**")
    if not _LEVENSHTEIN_AVAILABLE:
        st.warning("Библиотека python-Levenshtein не установлена. Расчет невозможен.")
    else:
        msg_lev, perc_lev = calculate_levenshtein_similarity(nat_text1_input, nat_text2_input)
        comparison_log.append(f"2.3 Natural vs Natural (Levenshtein): {msg_lev}")
        if perc_lev is not None:
            st.info(msg_lev)
            st.metric("Левенштейн Сходство", f"{perc_lev:.4f}")
            results['Natural vs Natural (Levenshtein)'] = perc_lev
        else:
            st.error(msg_lev)  # Используем error для ошибок
            st.metric("Левенштейн Сходство", "N/A")
            results['Natural vs Natural (Levenshtein)'] = None
        st.caption(
            "Измеряет сходство на основе минимального количества односимвольных правок (вставка, удаление, замена) для преобразования одного текста в другой. 1 = тексты идентичны, 0 = совершенно разные (или один пустой). Чувствительно к опечаткам и порядку символов.")

    st.markdown("---")

    # --- Генерация случайных текстов ---
    try:
        rand_letters1 = generate_random_letters(text_length)
        rand_letters2 = generate_random_letters(text_length)
        rand_words1 = generate_random_words(text_length)
        rand_words2 = generate_random_words(text_length)
        texts_used['Random Letters 1'] = rand_letters1
        texts_used['Random Letters 2'] = rand_letters2
        texts_used['Random Words 1'] = rand_words1
        texts_used['Random Words 2'] = rand_words2
    except Exception as e:
        st.error(f"Ошибка при генерации случайных текстов: {e}")
        st.stop()

    # --- Подготовка естественного текста 1 для сравнений 2 и 3 ---
    # Приводим к заданной длине text_length
    nat_text_aligned = None
    if not nat_text1_input:
        msg_nat_align = f"Предупреждение: Естественный текст 1 пуст. Сравнения с ним (случаи 2 и 3) будут пропущены."
        comparison_log.append(msg_nat_align)
        st.warning(msg_nat_align)
    else:
        len_nat1 = len(nat_text1_input)
        if len_nat1 == text_length:
            nat_text_aligned = nat_text1_input
            msg_nat_align = f"Естественный текст 1 имеет заданную длину {text_length}."
        elif len_nat1 > text_length:
            nat_text_aligned = nat_text1_input[:text_length]
            msg_nat_align = f"Естественный текст 1 (длина {len_nat1}) был усечен до длины {text_length} для сравнений 2 и 3."
            comparison_log.append(msg_nat_align)
            st.warning(msg_nat_align)
        else:
            nat_text_aligned = nat_text1_input.ljust(text_length)  # Дополняем пробелами справа
            msg_nat_align = f"Естественный текст 1 (длина {len_nat1}) был дополнен пробелами до длины {text_length} для сравнений 2 и 3."
            comparison_log.append(msg_nat_align)
            st.warning(msg_nat_align)

    texts_used['Natural Aligned (for 2, 3)'] = nat_text_aligned

    st.markdown("---")

    # 2. Естественный текст vs Случайные буквы
    st.subheader("2. Естественный текст vs Случайные буквы")
    if nat_text_aligned:
        msg, perc = compare_texts(nat_text_aligned, rand_letters1)
        comparison_log.append(f"2. Natural vs Random Letters: {msg}")
        st.info(msg)
        if perc is not None:
            st.metric("Процент совпадения", f"{perc:.4f}")
            results['Natural vs Random Letters'] = perc
        else:
            st.metric("Процент совпадения", "N/A")
            results['Natural vs Random Letters'] = None
    else:
        st.info("Сравнение пропущено, так как Естественный текст 1 не был предоставлен.")
        results['Natural vs Random Letters'] = None
    st.markdown("---")

    # 3. Естественный текст vs Случайные слова
    st.subheader("3. Естественный текст vs Случайные слова")
    if nat_text_aligned:
        msg, perc = compare_texts(nat_text_aligned, rand_words1)
        comparison_log.append(f"3. Natural vs Random Words: {msg}")
        st.info(msg)
        if perc is not None:
            st.metric("Процент совпадения", f"{perc:.4f}")
            results['Natural vs Random Words'] = perc
        else:
            st.metric("Процент совпадения", "N/A")
            results['Natural vs Random Words'] = None
    else:
        st.info("Сравнение пропущено, так как Естественный текст 1 не был предоставлен.")
        results['Natural vs Random Words'] = None
    st.markdown("---")

    # 4. Случайные буквы vs Случайные буквы
    st.subheader("4. Случайные буквы vs Случайные буквы")
    msg, perc = compare_texts(rand_letters1, rand_letters2)
    comparison_log.append(f"4. Random Letters vs Random Letters: {msg}")
    st.info(msg)
    if perc is not None:
        st.metric("Процент совпадения", f"{perc:.4f}")
        results['Random Letters vs Random Letters'] = perc
    else:
        st.metric("Процент совпадения", "N/A")
        results['Random Letters vs Random Letters'] = None
    st.markdown("---")

    # 5. Случайные слова vs Случайные слова
    st.subheader("5. Случайные слова vs Случайные слова")
    msg, perc = compare_texts(rand_words1, rand_words2)
    comparison_log.append(f"5. Random Words vs Random Words: {msg}")
    st.info(msg)
    if perc is not None:
        st.metric("Процент совпадения", f"{perc:.4f}")
        results['Random Words vs Random Words'] = perc
    else:
        st.metric("Процент совпадения", "N/A")
        results['Random Words vs Random Words'] = None
    st.markdown("---")

    # --- Начало Отчета ---
    st.header("Детальный Отчет")

    # --- Алгоритм Сравнения ---
    st.subheader("Алгоритм Сравнения Текстов")
    st.markdown(f"""
    **1. Посимвольное Сравнение:**
    Алгоритм предназначен для количественной оценки сходства двух текстов на основе посимвольного совпадения на одинаковых позициях.

    1.  **Проверка Длины:** На вход подаются две строки, `text1` и `text2`. Первым шагом вычисляются их длины, `len1` и `len2`.
    2.  **Обработка Неравной Длины:** Если `len1 != len2`, алгоритм сообщает об ошибке, указывает, какая строка длиннее и на сколько символов. Сравнение по данному методу в этом случае не производится, так как он требует строгого позиционного соответствия, которое невозможно при разной длине. Результат совпадения возвращается как `None`.
    3.  **Обработка Пустых Строк:** Если хотя бы одна из строк пустая (`len1 == 0` или `len2 == 0`), сравнение также невозможно. Алгоритм сообщает об этом, результат совпадения `None`.
    4.  **Посимвольное Сравнение (при равной длине):** Если строки имеют одинаковую ненулевую длину `L`, алгоритм итерирует по индексам от `0` до `L-1`. На каждой итерации `i` сравниваются символы `text1[i]` и `text2[i]`.
    5.  **Подсчет Совпадений:** Инициализируется счетчик совпадений `matches = 0`. Если `text1[i] == text2[i]`, счетчик `matches` увеличивается на 1.
    6.  **Расчет Процента Совпадений:** После прохода по всем символам вычисляется доля совпадений как отношение числа совпадений к общей длине строки: `percentage = matches / L`. Это значение находится в диапазоне от 0 (ни одного совпадения) до 1 (полное совпадение текстов).
    7.  **Возврат Результата:** Алгоритм возвращает информационное сообщение об успешности сравнения (указывая длину и число совпадений) и вычисленное значение `percentage`.

    **Пример:**
    `text1 = "кот"`
    `text2 = "кит"`
    Длины равны 3.
    - `k` == `k` (match = 1)
    - `о` != `и` (match = 1)
    - `т` == `т` (match = 2)
    Результат: `percentage = 2 / 3 ≈ 0.6667`
    
    **2. TF-IDF Косинусное Сходство:**
       - Представляет тексты как векторы в пространстве слов, где вес каждого слова зависит от его частоты в тексте (TF) и обратной частоты во всех сравниваемых текстах (IDF).
       - Результат: Косинус угла между векторами (обычно 0 до 1). 1 означает максимальное сходство по использованию важных слов, 0 - отсутствие общих значимых слов.
       - Игнорирует порядок слов, но учитывает их важность.
       - Хорошо подходит для поиска документов по ключевым словам.

    **3. Сходство на Основе Векторов (Embeddings):**
       - Использует предобученные модели (здесь - spaCy) для преобразования текстов в векторы фиксированной длины, отражающие их семантическое значение (смысл).
       - Результат: Косинусное сходство между векторами документов (от -1 до 1, чаще 0 до 1). 1 означает очень близкие по смыслу тексты.
       - Улавливает синонимы и контекстуальную близость слов.
       - Менее чувствителен к точному набору слов, чем TF-IDF.

    **4. Сходство Левенштейна (Нормализованное):**
       - Основано на расстоянии Левенштейна - минимальном количестве односимвольных операций (вставка, удаление, замена) для преобразования одной строки в другую.
       - Результат: Нормализованное значение `1 - (расстояние / макс_длина)` (от 0 до 1). 1 означает идентичные строки.
       - Очень чувствителен к порядку символов, опечаткам, небольшим изменениям.
       - Не учитывает смысл слов или текста. Подходит для сравнения коротких строк, поиска опечаток, оценки близости строк "как есть".
    """)

    # --- Примеры Текстов (из последнего запуска) ---
    st.subheader("Тексты, Использованные в Последнем Сравнении")
    max_display_len = text_length  # Покажем до 200 символов каждого текста
    for name, text in texts_used.items():
        if text is not None:
            display_text = text[:max_display_len] + ('...' if len(text) > max_display_len else '')
            st.text_area(f"{name} (Длина: {len(text)})", display_text, height=100, key=f"display_{name}", disabled=True)
        else:
            st.write(f"{name}: Текст отсутствовал или не использовался.")
    st.markdown("---")

    # --- Анализ Полученных Значений ---
    st.subheader("Анализ Результатов Сравнения")
    st.markdown(f"""
    Проанализируем типичные значения процента совпадений, полученные в ходе сравнения (на основе последнего запуска и общих соображений):

    *   **1. Естественный vs Естественный:**
        *   *Результат:* `{results.get('Natural vs Natural', 'N/A')}` (если сравнимы)
        *   *Ожидания и Анализ:* Значение сильно зависит от семантической и лексической близости текстов.
            *   Если тексты идентичны или очень похожи (например, разные редакции одного абзаца), процент будет высоким (близким к 1).
            *   Если тексты на одну тему, но разные, процент будет умеренным, т.к. будут совпадать пробелы, частые буквы (о, е, а, и, н, т...), возможно, некоторые короткие слова или окончания.
            *   Если тексты на совершенно разные темы, процент совпадения будет ниже, но все равно, как правило, выше, чем у случайных текстов, из-за общих структурных элементов языка (частотность букв, пробелы). Ожидаемое значение может быть в районе 0.05-0.15 для совершенно разных текстов на русском языке.
        - **Посимвольное:** Сильно зависит от идентичности строк. Обычно низкое, если тексты не копии друг друга. Растет с увеличением общих фраз или структуры.
        - **TF-IDF:** Умеренное или высокое, если тексты на одну тему и используют схожую лексику. Низкое, если темы разные.
        - **Embedding (spaCy):** Высокое, если тексты близки по смыслу, даже если использованы разные слова (синонимы). Может быть умеренным для текстов на одну общую тему, но с разными аспектами.
        - **Левенштейн:** Высокое только для почти идентичных текстов. Быстро падает при перестановке слов, синонимах, добавлении/удалении фрагментов. Полезно для оценки буквального совпадения.

    *   **2. Естественный vs Случайные буквы:**
        *   *Результат:* `{results.get('Natural vs Random Letters', 'N/A')}`
        *   *Ожидания и Анализ:* Ожидается очень низкий процент совпадений. Каждый символ в тексте из случайных букв выбирается независимо (в нашем случае, равновероятно из `{len(RUSSIAN_ALPHABET)}` символов: '{RUSSIAN_ALPHABET[:10]}...'). Вероятность случайного совпадения символа на любой позиции примерно равна `1 / len(RUSSIAN_ALPHABET)`, т.е. `1 / {len(RUSSIAN_ALPHABET)} ≈ {1 / len(RUSSIAN_ALPHABET):.4f}`. На длинных текстах реальный процент совпадений должен стремиться к этому значению. Небольшие отклонения связаны со статистической флуктуацией и неравномерным распределением частот букв в естественном тексте.

    *   **3. Естественный vs Случайные слова:**
        *   *Результат:* `{results.get('Natural vs Random Words', 'N/A')}`
        *   *Ожидания и Анализ:* Процент совпадений ожидается низким, но, вероятно, несколько выше, чем в случае со случайными буквами. Это связано с тем, что текст из случайных слов содержит много пробелов, которые также присутствуют в естественном тексте и могут совпадать по позиции. Также, если словарь `WORD_LIST` содержит частоупотребимые слова, есть небольшой шанс на совпадение целых коротких слов или их частей. Однако общая структура (порядок слов) случайна, поэтому процент совпадений остается низким, обычно не сильно превышая показатель для случайных букв.

    *   **4. Случайные буквы vs Случайные буквы:**
        *   *Результат:* `{results.get('Random Letters vs Random Letters', 'N/A')}`
        *   *Ожидания и Анализ:* Это классический случай сравнения двух независимых случайных последовательностей. Как и в случае 2, ожидаемый процент совпадений стремится к `1 / len(RUSSIAN_ALPHABET) ≈ {1 / len(RUSSIAN_ALPHABET):.4f}` при достаточно большой длине текста.

    *   **5. Случайные слова vs Случайные слова:**
        *   *Результат:* `{results.get('Random Words vs Random Words', 'N/A')}`
        *   *Ожидания и Анализ:* Ситуация похожа на случай 3. Два текста состоят из случайного набора слов из одного и того же словаря, разделенных пробелами. Процент совпадений будет определяться в основном вероятностью совпадения пробелов по позиции и, в меньшей степени, случайными совпадениями букв внутри несовпадающих слов или случайным совпадением одинаковых слов на одной позиции. Ожидаемое значение обычно чуть выше, чем `1 / len(RUSSIAN_ALPHABET)`, из-за структуры "слово-пробел", но все равно остается низким.

    **Вывод:** Данный метод сравнения чувствителен к позиционному совпадению символов. Он хорошо отличает структурированные (естественные) тексты от случайных последовательностей, но его значение для сравнения осмысленных текстов ограничено, так как он не учитывает семантику, перестановку слов или синонимы. Для содержательного сравнения текстов обычно используются более сложные методы (например, TF-IDF, векторные представления слов/текстов, расстояние Левенштейна и т.д.).
    - Разные метрики измеряют разные аспекты сходства.
    - Посимвольное сравнение - самое "примитивное", чувствительное к малейшим отличиям.
    - Левенштейн хорош для оценки буквальной близости строк.
    - TF-IDF оценивает лексическое сходство (общие слова).
    - Векторные представления (Embeddings) оценивают семантическое (смысловое) сходство.
    - Выбор метрики зависит от конкретной задачи сравнения текстов.
    
    """)
    st.markdown("---")

    # --- Соображения о Длине Текста ---
    st.subheader("Соображения о Достаточной Длине Текста")
    st.markdown(f"""
    Выбор длины текста (`L`) для сравнения важен для получения статистически значимых и стабильных результатов.

    
    *   **Посимвольное сравнение:** Требует одинаковой длины. Статистическая значимость результата растет с длиной.
    *   **Левенштейн:** Не требует одинаковой длины. Результат (особенно нормализованный) более стабилен на длинных текстах.
    *   **TF-IDF:** Работает лучше на текстах, содержащих достаточное количество слов для оценки их частот (хотя бы несколько предложений). Очень короткие тексты могут дать нерепрезентативные векторы.
    *   **Embeddings (spaCy):** Модели обучены на больших корпусах. Они могут дать осмысленные векторы даже для коротких фраз или предложений. Однако надежность оценки сходства целых документов растет с их длиной.

    **Рекомендации по длине для разных методов:**
    - **Посимвольное/Левенштейн:** От десятков до тысяч символов. Стабильность растет с длиной.
    - **TF-IDF:** Желательно от 50-100 слов и больше.
    - **Embeddings:** Могут работать и на коротких текстах, но лучше для оценки сходства документов - от нескольких предложений до абзацев и более.

    *   **Короткие тексты (L < 50-100 символов):**
        *   Результаты сильно подвержены случайным флуктуациям. Несколько случайных совпадений или несовпадений могут кардинально изменить процент.
        *   Различия между разными типами сравнений (например, Естественный vs Случайные буквы и Случайные буквы vs Случайные буквы) могут быть нечеткими.
        *   Не подходят для надежных выводов.

    *   **Средние тексты (L = 100-1000 символов):**
        *   Результаты становятся более стабильными. Влияние отдельных случайных совпадений уменьшается.
        *   Начинают проявляться закономерности, предсказанные теорией вероятностей (например, процент совпадения для случайных текстов приближается к `1 / {len(RUSSIAN_ALPHABET)}`).
        *   Различия между типами пар текстов становятся более выраженными. Длина в несколько сотен символов (как `L={text_length}` в текущем запуске) уже позволяет увидеть характерные различия.

    *   **Длинные тексты (L > 1000 символов):**
        *   Результаты максимально приближаются к теоретически ожидаемым значениям (по закону больших чисел). Статистическая погрешность минимальна.
        *   Позволяют выявлять даже небольшие различия в структуре или статистических свойствах текстов.
        *   Являются предпочтительными для серьезного анализа, особенно если требуется высокая точность или сравнение текстов с похожими характеристиками.

    **Какая длина достаточна?**

    *   Для **демонстрационных целей** и чтобы увидеть качественные различия между пятью сценариями, длины в **200-500 символов** обычно достаточно.
    *   Для **более надежного статистического анализа**, особенно для различения текстов с не сильно отличающимися свойствами (например, два разных естественных текста), рекомендуется использовать тексты длиной **не менее 1000 символов**, а лучше – несколько тысяч.
    *   В **криптографии**, при анализе случайности генераторов псевдослучайных чисел (которые можно представить как тексты из случайных символов), используются очень большие последовательности (миллионы и миллиарды символов/бит) и сложные статистические тесты для выявления малейших отклонений от идеальной случайности.

    **Вывод:** Для задачи демонстрации различий между указанными типами пар текстов, выбранная по умолчанию длина `{text_length}` или любая длина в несколько сотен символов является адекватной. Для исследовательских целей требуется значительно большая длина.
    Для комплексного анализа с использованием TF-IDF и Embeddings, желательно использовать тексты длиной хотя бы в несколько предложений или абзац. Для посимвольного сравнения и Левенштейна длина может быть любой, но результаты на очень коротких строках могут быть менее показательными. Длина `{text_length}` для случайных текстов достаточна для демонстрации.
    """)
    st.markdown("---")

    # Показываем лог выполнения для отладки и информации
    with st.expander("Показать лог выполнения сравнений"):
        for log_entry in comparison_log:
            st.text(log_entry)

else:
    st.info(
        "Настройте параметры в боковой панели и нажмите кнопку 'Запустить Сравнение и Анализ' для получения результатов.")
    if not _SKLEARN_AVAILABLE:
        st.warning("Библиотека scikit-learn не установлена. TF-IDF будет недоступен.")
    if not _SPACY_AVAILABLE:
        st.warning("Библиотека spaCy не установлена. Сравнение на основе векторов будет недоступно.")
    if not _LEVENSHTEIN_AVAILABLE:
        st.warning("Библиотека python-Levenshtein не установлена. Сравнение Левенштейна будет недоступно.")
